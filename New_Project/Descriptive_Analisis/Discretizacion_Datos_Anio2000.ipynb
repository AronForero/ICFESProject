{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Procesado de Datos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Año 2000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "%matplotlib inline\n",
    "%run -i ../tools/functions.py\n",
    "%run -i ../tools/label_encoder.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Charge the file with the data, into a DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data_2000 = pd.read_csv(\"../DatosFTPICFES/SABER11/SB11-BASES_DE_DATOS/SB11-20001-RGSTRO-CLFCCN-V1-0.txt\", delimiter=\"|\",\n",
    "                        encoding=\"iso-8859-1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "data_2000.head(3).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data_2000['FAMI_PERSONAS_HOGAR'].value_counts().sort_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The simbol \"@\" will be changed for the number 4, because the average in Colombian's homes is near to 4."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_2000 = letters_to_num(data_2000, [\"@\"], [\"4\"], \"FAMI_PERSONAS_HOGAR\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, the following columns will be reviewed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data_2000['FAMI_VIVIENDA_PROPIA'].value_counts().sort_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are very few rows with the value \"@\", so the rows that has it will be deleted. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data_2000 = drop_lines(data_2000, \"FAMI_VIVIENDA_PROPIA\", \"@\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data_2000['FAMI_DEUDA_VIVIENDA'].value_counts().sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_2000 = drop_lines(data_2000, \"FAMI_DEUDA_VIVIENDA\", \"@\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data_2000['FAMI_LEE_ESCRIBE_PADRE'].value_counts().sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_2000 = drop_lines(data_2000, \"FAMI_LEE_ESCRIBE_PADRE\", \"@\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data_2000['FAMI_LEE_ESCRIBE_MADRE'].value_counts().sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_2000 = drop_lines(data_2000, \"FAMI_LEE_ESCRIBE_MADRE\", \"@\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data_2000['FAMI_SOST_PERSONAL'].value_counts().sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_2000 = drop_lines(data_2000, \"FAMI_SOST_PERSONAL\", \"@\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data_2000['ESTU_TRABAJA'].value_counts().sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_2000 = drop_lines(data_2000, \"ESTU_TRABAJA\", \"@\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data_2000['COLE_CALENDARIO'].value_counts().sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data_2000['COLE_CARACTER'].value_counts().sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "remaining_c = data_2000.columns.difference(['FAMI_PERSONAS_HOGAR', 'FAMI_VIVIENDA_PROPIA', 'FAMI_DEUDA_VIVIENDA', 'FAMI_LEE_ESCRIBE_PADRE',\n",
    "                     'FAMI_LEE_ESCRIBE_MADRE', 'FAMI_SOST_PERSONAL', 'ESTU_TRABAJA', 'COLE_CALENDARIO',\n",
    "                     'COLE_CARACTER'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "remaining_c"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Columnas:\n",
    "- COD_IDIOMA: BIEN, int64\n",
    "- COD_INTERDISCIPLINAR: Bien, int64\n",
    "- COLE_BILINGUE: Bien, float64\n",
    "- COLE_COD_ICFES: Bien, int64\n",
    "- COLE_DEPTO_UBICACION: Bien, **OBJECT**\n",
    "- COLE_JORNADA: Bien, **OBJECT**\n",
    "- COLE_MCPIO_UBICACION: Bien, **OBJECT**\n",
    "- COLE_NOMBRE_SEDE: Bien, **OBJECT**\n",
    "- COLE_VALOR_PENSION: existen VALORES NaN, str **REVISAR**\n",
    "- ESTU_ACT_PROX_ANNO: existen @ que se cambiaron por el valor 4 que falta, **OBJECT**\n",
    "- ESTU_CARRDESEADA_RAZON: existen valores NaN, str **REVISAR**\n",
    "- ESTU_DEPTO_PRESENTACION: Bien, **OBJECT**\n",
    "- ESTU_GENERO: Bien, **OBJECT**\n",
    "- ESTU_LIMITA_INVIDENTE: Bien, **OBJECT**, Muchos valores NaN\n",
    "- ESTU_LIMITA_MOTRIZ: Bien, **OBJECT**, Muchos valores NaN\n",
    "- ESTU_LIMITA_SORDONOINTERPRETE: Bien, **OBJECT**, Muchos valores NaN\n",
    "- ESTU_MCPIO_PRESENTACION: Bien, **OBJECT**\n",
    "- ESTU_NACIMIENTO_ANNO: Bien, Float64, Se eliminaron algunas filas porque no tenian logica (años 195, 196, 197, 198)\n",
    "- ESTU_NACIMIENTO_DIA: Bien, Float64\n",
    "- ESTU_NACIMIENTO_MES: Bien, Float64\n",
    "- ESTU_RAZONINSTITUTO: Valores 'nan', ***REVISAR***\n",
    "- ESTU_RESIDE_DEPTO: Bien, **OBJECT**\n",
    "- ESTU_RESIDE_MCPIO: Bien, **OBJECT**\n",
    "- ESTU_TIPO_DOCUMENTO: Bien, **OBJECT**\n",
    "- FAMI_APORTANTES: Bien, **OBJECT**, se eliminan las filas que poseen '@' y se cambia el '+' por '+9'\n",
    "- FAMI_EDUCA_MADRE: Bien, **OBJECT**, se eliminan las filas que poseen '@'\n",
    "- FAMI_EDUCA_PADRE: Bien, **OBJECT**, se eliminan las filas que poseen '@'\n",
    "- FAMI_INGRESO_FMILIAR_MENSUAL: Bien, **OBJECT**, se eliminan las filas que poseen '@'\n",
    "- FAMI_NUM_HERMANOS: Bien, **OBJECT**, se eliminan las filas que poseen '@' y se cambia el '+' por '+10'\n",
    "- FAMI_NUM_HERMANOS_EDUSUPERIOR: Bien, **OBJECT**, se eliminan las filas que poseen '@' y se cambia el + por '+10'\n",
    "- FAMI_OCUPA_MADRE: Bien, **OBJECT** se eliminan las filas que poseen '@'\n",
    "- FAMI_OCUPA_PADRE: Bien, **OBJECT** se eliminan las filas que poseen '@'\n",
    "- FAMI_POSICION_HERMANOS: Bien **OBJECT**, se eliminan las filas que poseen '@' y se cambia el '+' por '+10'\n",
    "- PUNT_BIOLOGIA: Bien, **OBJECT**\n",
    "- PUNT_FILOSOFIA: Bien, **OBJECT**\n",
    "- PUNT_FISICA: Bien, **OBJECT**\n",
    "- PUNT_GEOGRAFIA: Bien, **OBJECT**\n",
    "- PUNT_HISTORIA: Bien, **OBJECT**\n",
    "- PUNT_IDIOMA: Bien, **OBJECT**\n",
    "- PUNT_INTERDISCIPLINAR: Bien, **OBJECT**\n",
    "- PUNT_LENGUAJE: Bien, **OBJECT**\n",
    "- PUNT_MATEMATICAS: Bien, **OBJECT**\n",
    "- PUNT_QUIMICA: Bien, **OBJECT**\n",
    "___________________\n",
    "\n",
    "ELIMINACIONES\n",
    "\n",
    "- ESTU_CONSECUTIVO: Eliminada. no aporta para la prediccion ***ELIMINADA***\n",
    "- ESTU_CARRDESEADA_COD: Datos con errores y demasiadas inconsistencias, ***ELIMINADA***\n",
    "- ESTU_IES_COD_DESEADA: Datos con errores y demasiadas inconsistencias, ***ELIMINADA***\n",
    "- ESTU_LIMITA_SORDOINTERPRETE: No tiene valores en ninguna fila, ***ELIMINADA***\n",
    "- IND_ANNO_TERMINO_BACHILLERATO: Datos con errores y demasiadas inconsistencias. ***ELIMINADA***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cambio de la @ por 4 en la columna *ESTU_ACT_PROX_ANNO*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data_2000['ESTU_ACT_PROX_ANNO'].value_counts().sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data_2000['ESTU_ACT_PROX_ANNO'] = data_2000['ESTU_ACT_PROX_ANNO'].replace('@', '4')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se eliminan las lineas que tienen años invalidos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data_2000 = drop_lines(data_2000, 'ESTU_NACIMIENTO_ANNO', 195.0)\n",
    "data_2000 = drop_lines(data_2000, 'ESTU_NACIMIENTO_ANNO', 196.0)\n",
    "data_2000 = drop_lines(data_2000, 'ESTU_NACIMIENTO_ANNO', 197.0)\n",
    "data_2000 = drop_lines(data_2000, 'ESTU_NACIMIENTO_ANNO', 198.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se hacen los cambios segun la columna FAMI_APORTANTES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_2000 = drop_lines(data_2000, 'FAMI_APORTANTES', '@')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_2000['FAMI_APORTANTES'] = data_2000['FAMI_APORTANTES'].replace('+', '+9')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se eliminan las filas que poseen '@' FAMI_EDUCA_MADRE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_2000 = drop_lines(data_2000, 'FAMI_EDUCA_MADRE', '@')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se eliminan las filas que poseen '@' en FAMI_EDUCA_PADRE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_2000 = drop_lines(data_2000, 'FAMI_EDUCA_PADRE', '@')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se eliminan las filas que poseen '@' en FAMI_INGRESO_FMILIAR_MENSUAL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_2000 = drop_lines(data_2000, 'FAMI_INGRESO_FMILIAR_MENSUAL', '@')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se eliminan las filas que poseen '@' y se cambia el '+' por '+10' en FAMI_NUM_HERMANOS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_2000 = drop_lines(data_2000, 'FAMI_NUM_HERMANOS', '@')\n",
    "data_2000['FAMI_NUM_HERMANOS'] = data_2000['FAMI_NUM_HERMANOS'].replace('+', '+10')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#lo mismo que la anterior pero en FAMI_NUM_HERMANOS_EDUSUPERIOR\n",
    "data_2000 = drop_lines(data_2000, 'FAMI_NUM_HERMANOS_EDUSUPERIOR', '@')\n",
    "data_2000['FAMI_NUM_HERMANOS_EDUSUPERIOR'] = data_2000['FAMI_NUM_HERMANOS_EDUSUPERIOR'].replace('+', '+10')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#se eliminan las filas que poseen el valor '@'\n",
    "data_2000 = drop_lines(data_2000, 'FAMI_OCUPA_MADRE', '@')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#se eliminan las filas que poseen el valor '@'\n",
    "data_2000 = drop_lines(data_2000, 'FAMI_OCUPA_PADRE', '@')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Se eliminan las filas que tienen valores '@' y se cambia '+' por '+10'\n",
    "data_2000 = drop_lines(data_2000, 'FAMI_POSICION_HERMANOS', '@')\n",
    "data_2000['FAMI_POSICION_HERMANOS'] = data_2000['FAMI_POSICION_HERMANOS'].replace('+', '+10')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Deletion of the selected columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_2000 = data_2000.drop(['ESTU_CARRDESEADA_COD', 'ESTU_IES_COD_DESEADA', 'ESTU_LIMITA_SORDOINTERPRETE',\n",
    " 'IND_ANNO_TERMINO_BACHILLERATO'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___________"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___________"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___________"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# En este momento ya estaria listo el primer archivo, para su posterior uso en un modelo de prediccion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "LR = LinearRegression()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data will be prepared to be splitted into **X** and **y**  \n",
    "\n",
    "The first step is encode the data. The result will be stored in a new DataFram called ***encoded_data***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "encoded_data = pd.DataFrame.copy(data_2000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "encoded_data = label_encoder(encoded_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "But, this function just modified the columns that has dtype = object, so i have to check the other columns. \n",
    "The COLE_BILINGUE column, is a Float64 dtype and the function doesn't affected it.  \n",
    "The solution is replace the NaN values found in the column and changes it for the \"0\" to indicate that the school is not Bilingual."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"Now i fix the problem with the COLE_BILINGUE\"\"\"\n",
    "encoded_data = letters_to_num(encoded_data, \"NaN\", \"0\", \"COLE_BILINGUE\")\n",
    "data_2000 = letters_to_num(data_2000, 'NaN', '0', 'COLE_BILINGUE')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So now, using the function ***missing_data*** located in the file called ***functions.py***, we can check the whole DataFrame to discover another columns with NaN values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "missing_data(encoded_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "The NaN values are located in the columns related to the student's birth date.  \n",
    "And one important thing we can see in the result is that when one column is NaN the other two column are NaN too, so we can delete this 14 columns with not so much troubles.  \n",
    "I just found one exception in the row number 55189, that just the Year is NaN.  \n",
    "BUT i have to delete this in the encoded DataFrame ***encoded_data*** to split the data and avoid some troubles that can appear.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "encoded_data.loc[encoded_data['ESTU_NACIMIENTO_ANNO'].isnull()]\n",
    "#ESTU_NACIMIENTO_MES\n",
    "#ESTU_NACIMIENTO_ANNO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\"\"\"First i have to put the NaN values as a Number because of the column's dtype\"\"\"\n",
    "encoded_data = letters_to_num(encoded_data, \"NaN\", \"-1\", \"ESTU_NACIMIENTO_ANNO\")\n",
    "data_2000 = letters_to_num(data_2000, 'NaN', '-1', 'ESTU_NACIMIENTO_ANNO')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\"\"\"Then i can delete the lines\"\"\"\n",
    "encoded_data = drop_lines(encoded_data, 'ESTU_NACIMIENTO_ANNO', '-1')\n",
    "data_2000 = drop_lines(data_2000, 'ESTU_NACIMIENTO_ANNO', '-1')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Now it's time for a little test with sklearn linear regression**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now it's time to exclude columns that do not serve us for our objective as the student's consecutive.  \n",
    "- COLE_COD_ICFES\n",
    "- COLE_NOMBRE_SEDE\n",
    "- ESTU_TIPO_DOCUMENTO  \n",
    "\n",
    "Also the data is divided for train [0, 50000] and for test [50000,73551]."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(\"Shape of the original DF:\", data_2000.shape)\n",
    "print(\"Shape of the encoded DF:\", encoded_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "y = data_2000.filter(items = ['PUNT_BIOLOGIA', 'PUNT_MATEMATICAS', 'PUNT_FILOSOFIA', 'PUNT_FISICA', 'PUNT_HISTORIA',\n",
    "                     'PUNT_QUIMICA', 'PUNT_LENGUAJE', 'PUNT_GEOGRAFIA', 'PUNT_IDIOMA', 'PUNT_INTERDISCIPLINAR'], axis=1)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, Now I have a DataFrame with all the posible targets that will be taken into account for the work"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"I split the data into X_train and y_train, taking just the corresponding columns\"\"\"\n",
    "X_train = encoded_data.loc[:50000, 'COLE_COD_ICFES':]\n",
    "y_train = y.loc[:50000, 'PUNT_MATEMATICAS'] #i take the score in Maths\n",
    "###########################################################################################\n",
    "\"\"\"Now, i delete the columns that are not useful to the work\"\"\"\n",
    "X_train = X_train.drop(['COLE_COD_ICFES', 'COLE_NOMBRE_SEDE', 'ESTU_TIPO_DOCUMENTO'], axis=1)\n",
    "\"\"\"Now it's time to drop the others subject's scores, because this is what i want to predict\"\"\"\n",
    "X_train = X_train.drop(['PUNT_BIOLOGIA', 'PUNT_MATEMATICAS', 'PUNT_FILOSOFIA', 'PUNT_FISICA', \n",
    "                        'PUNT_HISTORIA', 'PUNT_QUIMICA', 'PUNT_LENGUAJE', 'PUNT_GEOGRAFIA', 'PUNT_IDIOMA',\n",
    "                        'PUNT_INTERDISCIPLINAR'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(data_2000.shape, encoded_data.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First try to predict one subject score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "LR.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now i can prepare the Data to test the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"I split the data into X_test and y_test, taking just the corresponding columns\"\"\"\n",
    "X_test = encoded_data.loc[50000:, 'COLE_COD_ICFES':]\n",
    "y_test = y.loc[50000:, 'PUNT_MATEMATICAS'] #i take the score in Maths\n",
    "\"\"\"Now, i delete the columns that are not useful to the work\"\"\"\n",
    "X_test = X_test.drop(['COLE_COD_ICFES', 'COLE_NOMBRE_SEDE', 'ESTU_TIPO_DOCUMENTO'], axis=1)\n",
    "\"\"\"Now it's time to drop the others subject's scores, because this is what i want to predict\"\"\"\n",
    "X_test = X_test.drop(['PUNT_BIOLOGIA', 'PUNT_MATEMATICAS', 'PUNT_FILOSOFIA', 'PUNT_FISICA', \n",
    "                        'PUNT_HISTORIA', 'PUNT_QUIMICA', 'PUNT_LENGUAJE', 'PUNT_GEOGRAFIA', 'PUNT_IDIOMA',\n",
    "                        'PUNT_INTERDISCIPLINAR'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "LR.score(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "LR.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I have to do a reshape in the sample that i pass to the predictor because the functions ask for it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "LR.predict(X_test.iloc[123].reshape(1,-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "y_test.iloc[123]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here i can plot a figure to see the behavior of the target.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(18, 4))\n",
    "plt.plot(y['PUNT_MATEMATICAS'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "About that figure ploted above, i can see that the behavior of the target is so chaotic and is dificult to predict with a simple Linear Regression."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# The second file is the 2000_2 that correspond to the second period of the year."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.5/site-packages/IPython/core/interactiveshell.py:2723: DtypeWarning: Columns (5,7,12,13,15,16) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    }
   ],
   "source": [
    "data_2000_2 = pd.read_csv(\"../DatosFTPICFES/SABER11/SB11-BASES_DE_DATOS/SB11-20002-RGSTRO-CLFCCN-V1-0.txt\", delimiter=\"|\",\n",
    "                         encoding=\"iso-8859-1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(354862, 58)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_2000_2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>ESTU_CONSECUTIVO</th>\n",
       "      <td>SB11200020145911</td>\n",
       "      <td>SB11200020210439</td>\n",
       "      <td>SB11200020155853</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>COLE_COD_ICFES</th>\n",
       "      <td>75648</td>\n",
       "      <td>364</td>\n",
       "      <td>56820</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>COLE_NOMBRE_SEDE</th>\n",
       "      <td>LICEO ALCALDIA DE MEDELLIN</td>\n",
       "      <td>COLEGIO MARIA AUXILIADORA</td>\n",
       "      <td>INSTITUTO TECNOLOGICO METROPOLITANO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>IND_ANNO_TERMINO_BACHILLERATO</th>\n",
       "      <td>2000</td>\n",
       "      <td>2000</td>\n",
       "      <td>2000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>COLE_JORNADA</th>\n",
       "      <td>M</td>\n",
       "      <td>C</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>COLE_VALOR_PENSION</th>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ESTU_GENERO</th>\n",
       "      <td>F</td>\n",
       "      <td>F</td>\n",
       "      <td>F</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ESTU_NACIMIENTO_DIA</th>\n",
       "      <td>2</td>\n",
       "      <td>27</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ESTU_NACIMIENTO_MES</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ESTU_NACIMIENTO_ANNO</th>\n",
       "      <td>1984</td>\n",
       "      <td>1984</td>\n",
       "      <td>1978</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ESTU_DEPTO_PRESENTACION</th>\n",
       "      <td>ANTIOQUIA</td>\n",
       "      <td>ANTIOQUIA</td>\n",
       "      <td>ANTIOQUIA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ESTU_MCPIO_PRESENTACION</th>\n",
       "      <td>MEDELLIN</td>\n",
       "      <td>MEDELLIN</td>\n",
       "      <td>MEDELLIN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ESTU_ETNIA</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ESTU_LIMITA_INVIDENTE</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ESTU_LIMITA_SORDOINTERPRETE</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ESTU_LIMITA_SORDONOINTERPRETE</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ESTU_LIMITA_MOTRIZ</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PUNT_BIOLOGIA</th>\n",
       "      <td>49</td>\n",
       "      <td>48</td>\n",
       "      <td>42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PUNT_MATEMATICAS</th>\n",
       "      <td>39</td>\n",
       "      <td>47</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PUNT_FILOSOFIA</th>\n",
       "      <td>48</td>\n",
       "      <td>57</td>\n",
       "      <td>53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PUNT_FISICA</th>\n",
       "      <td>44</td>\n",
       "      <td>52</td>\n",
       "      <td>44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PUNT_HISTORIA</th>\n",
       "      <td>46</td>\n",
       "      <td>46</td>\n",
       "      <td>46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PUNT_QUIMICA</th>\n",
       "      <td>47</td>\n",
       "      <td>38</td>\n",
       "      <td>42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PUNT_LENGUAJE</th>\n",
       "      <td>55</td>\n",
       "      <td>52</td>\n",
       "      <td>43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PUNT_GEOGRAFIA</th>\n",
       "      <td>40</td>\n",
       "      <td>49</td>\n",
       "      <td>45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>COD_INTERDISCIPLINAR</th>\n",
       "      <td>43</td>\n",
       "      <td>43</td>\n",
       "      <td>43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PUNT_INTERDISCIPLINAR</th>\n",
       "      <td>51</td>\n",
       "      <td>25</td>\n",
       "      <td>44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>COD_IDIOMA</th>\n",
       "      <td>51</td>\n",
       "      <td>51</td>\n",
       "      <td>51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PUNT_IDIOMA</th>\n",
       "      <td>37</td>\n",
       "      <td>42</td>\n",
       "      <td>43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ESTU_IES_COD_DESEADA</th>\n",
       "      <td>NaN</td>\n",
       "      <td>1712</td>\n",
       "      <td>1201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ESTU_RAZONINSTITUTO</th>\n",
       "      <td>NaN</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ESTU_CARRDESEADA_COD</th>\n",
       "      <td>NaN</td>\n",
       "      <td>48117</td>\n",
       "      <td>12136</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ESTU_CARRDESEADA_RAZON</th>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FAMI_PERSONAS_HOGAR</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FAMI_VIVIENDA_PROPIA</th>\n",
       "      <td>S</td>\n",
       "      <td>S</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FAMI_DEUDA_VIVIENDA</th>\n",
       "      <td>N</td>\n",
       "      <td>NaN</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FAMI_APORTANTES</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FAMI_INGRESO_FMILIAR_MENSUAL</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FAMI_LEE_ESCRIBE_PADRE</th>\n",
       "      <td>S</td>\n",
       "      <td>S</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FAMI_LEE_ESCRIBE_MADRE</th>\n",
       "      <td>S</td>\n",
       "      <td>S</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FAMI_EDUCA_PADRE</th>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FAMI_EDUCA_MADRE</th>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FAMI_OCUPA_PADRE</th>\n",
       "      <td>09</td>\n",
       "      <td>04</td>\n",
       "      <td>08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FAMI_OCUPA_MADRE</th>\n",
       "      <td>09</td>\n",
       "      <td>04</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FAMI_NUM_HERMANOS</th>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FAMI_NUM_HERMANOS_EDUSUPERIOR</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FAMI_POSICION_HERMANOS</th>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FAMI_SOST_PERSONAL</th>\n",
       "      <td>T</td>\n",
       "      <td>T</td>\n",
       "      <td>T</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ESTU_TRABAJA</th>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ESTU_ACT_PROX_ANNO</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>COLE_CALENDARIO</th>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>F</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>COLE_BILINGUE</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>COLE_CARACTER</th>\n",
       "      <td>ACADEMICO</td>\n",
       "      <td>ACADEMICO</td>\n",
       "      <td>ACADEMICO Y TECNICO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>COLE_DEPTO_UBICACION</th>\n",
       "      <td>ANTIOQUIA</td>\n",
       "      <td>ANTIOQUIA</td>\n",
       "      <td>ANTIOQUIA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>COLE_MCPIO_UBICACION</th>\n",
       "      <td>MEDELLIN</td>\n",
       "      <td>MEDELLIN</td>\n",
       "      <td>MEDELLIN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ESTU_TIPO_DOCUMENTO</th>\n",
       "      <td>T</td>\n",
       "      <td>T</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ESTU_RESIDE_DEPTO</th>\n",
       "      <td>ANTIOQUIA</td>\n",
       "      <td>ANTIOQUIA</td>\n",
       "      <td>ANTIOQUIA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ESTU_RESIDE_MCPIO</th>\n",
       "      <td>MEDELLIN</td>\n",
       "      <td>MEDELLIN</td>\n",
       "      <td>MEDELLIN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                        0  \\\n",
       "ESTU_CONSECUTIVO                         SB11200020145911   \n",
       "COLE_COD_ICFES                                      75648   \n",
       "COLE_NOMBRE_SEDE               LICEO ALCALDIA DE MEDELLIN   \n",
       "IND_ANNO_TERMINO_BACHILLERATO                        2000   \n",
       "COLE_JORNADA                                            M   \n",
       "COLE_VALOR_PENSION                                      8   \n",
       "ESTU_GENERO                                             F   \n",
       "ESTU_NACIMIENTO_DIA                                     2   \n",
       "ESTU_NACIMIENTO_MES                                     1   \n",
       "ESTU_NACIMIENTO_ANNO                                 1984   \n",
       "ESTU_DEPTO_PRESENTACION                         ANTIOQUIA   \n",
       "ESTU_MCPIO_PRESENTACION                          MEDELLIN   \n",
       "ESTU_ETNIA                                            NaN   \n",
       "ESTU_LIMITA_INVIDENTE                                 NaN   \n",
       "ESTU_LIMITA_SORDOINTERPRETE                           NaN   \n",
       "ESTU_LIMITA_SORDONOINTERPRETE                         NaN   \n",
       "ESTU_LIMITA_MOTRIZ                                    NaN   \n",
       "PUNT_BIOLOGIA                                          49   \n",
       "PUNT_MATEMATICAS                                       39   \n",
       "PUNT_FILOSOFIA                                         48   \n",
       "PUNT_FISICA                                            44   \n",
       "PUNT_HISTORIA                                          46   \n",
       "PUNT_QUIMICA                                           47   \n",
       "PUNT_LENGUAJE                                          55   \n",
       "PUNT_GEOGRAFIA                                         40   \n",
       "COD_INTERDISCIPLINAR                                   43   \n",
       "PUNT_INTERDISCIPLINAR                                  51   \n",
       "COD_IDIOMA                                             51   \n",
       "PUNT_IDIOMA                                            37   \n",
       "ESTU_IES_COD_DESEADA                                  NaN   \n",
       "ESTU_RAZONINSTITUTO                                   NaN   \n",
       "ESTU_CARRDESEADA_COD                                  NaN   \n",
       "ESTU_CARRDESEADA_RAZON                                NaN   \n",
       "FAMI_PERSONAS_HOGAR                                     4   \n",
       "FAMI_VIVIENDA_PROPIA                                    S   \n",
       "FAMI_DEUDA_VIVIENDA                                     N   \n",
       "FAMI_APORTANTES                                         2   \n",
       "FAMI_INGRESO_FMILIAR_MENSUAL                            1   \n",
       "FAMI_LEE_ESCRIBE_PADRE                                  S   \n",
       "FAMI_LEE_ESCRIBE_MADRE                                  S   \n",
       "FAMI_EDUCA_PADRE                                        4   \n",
       "FAMI_EDUCA_MADRE                                        4   \n",
       "FAMI_OCUPA_PADRE                                       09   \n",
       "FAMI_OCUPA_MADRE                                       09   \n",
       "FAMI_NUM_HERMANOS                                       6   \n",
       "FAMI_NUM_HERMANOS_EDUSUPERIOR                           0   \n",
       "FAMI_POSICION_HERMANOS                                  6   \n",
       "FAMI_SOST_PERSONAL                                      T   \n",
       "ESTU_TRABAJA                                            N   \n",
       "ESTU_ACT_PROX_ANNO                                      3   \n",
       "COLE_CALENDARIO                                         A   \n",
       "COLE_BILINGUE                                         NaN   \n",
       "COLE_CARACTER                                   ACADEMICO   \n",
       "COLE_DEPTO_UBICACION                            ANTIOQUIA   \n",
       "COLE_MCPIO_UBICACION                             MEDELLIN   \n",
       "ESTU_TIPO_DOCUMENTO                                     T   \n",
       "ESTU_RESIDE_DEPTO                               ANTIOQUIA   \n",
       "ESTU_RESIDE_MCPIO                                MEDELLIN   \n",
       "\n",
       "                                                       1  \\\n",
       "ESTU_CONSECUTIVO                        SB11200020210439   \n",
       "COLE_COD_ICFES                                       364   \n",
       "COLE_NOMBRE_SEDE               COLEGIO MARIA AUXILIADORA   \n",
       "IND_ANNO_TERMINO_BACHILLERATO                       2000   \n",
       "COLE_JORNADA                                           C   \n",
       "COLE_VALOR_PENSION                                     5   \n",
       "ESTU_GENERO                                            F   \n",
       "ESTU_NACIMIENTO_DIA                                   27   \n",
       "ESTU_NACIMIENTO_MES                                    4   \n",
       "ESTU_NACIMIENTO_ANNO                                1984   \n",
       "ESTU_DEPTO_PRESENTACION                        ANTIOQUIA   \n",
       "ESTU_MCPIO_PRESENTACION                         MEDELLIN   \n",
       "ESTU_ETNIA                                           NaN   \n",
       "ESTU_LIMITA_INVIDENTE                                NaN   \n",
       "ESTU_LIMITA_SORDOINTERPRETE                          NaN   \n",
       "ESTU_LIMITA_SORDONOINTERPRETE                        NaN   \n",
       "ESTU_LIMITA_MOTRIZ                                   NaN   \n",
       "PUNT_BIOLOGIA                                         48   \n",
       "PUNT_MATEMATICAS                                      47   \n",
       "PUNT_FILOSOFIA                                        57   \n",
       "PUNT_FISICA                                           52   \n",
       "PUNT_HISTORIA                                         46   \n",
       "PUNT_QUIMICA                                          38   \n",
       "PUNT_LENGUAJE                                         52   \n",
       "PUNT_GEOGRAFIA                                        49   \n",
       "COD_INTERDISCIPLINAR                                  43   \n",
       "PUNT_INTERDISCIPLINAR                                 25   \n",
       "COD_IDIOMA                                            51   \n",
       "PUNT_IDIOMA                                           42   \n",
       "ESTU_IES_COD_DESEADA                                1712   \n",
       "ESTU_RAZONINSTITUTO                                    7   \n",
       "ESTU_CARRDESEADA_COD                               48117   \n",
       "ESTU_CARRDESEADA_RAZON                                 3   \n",
       "FAMI_PERSONAS_HOGAR                                    4   \n",
       "FAMI_VIVIENDA_PROPIA                                   S   \n",
       "FAMI_DEUDA_VIVIENDA                                  NaN   \n",
       "FAMI_APORTANTES                                        1   \n",
       "FAMI_INGRESO_FMILIAR_MENSUAL                           1   \n",
       "FAMI_LEE_ESCRIBE_PADRE                                 S   \n",
       "FAMI_LEE_ESCRIBE_MADRE                                 S   \n",
       "FAMI_EDUCA_PADRE                                       7   \n",
       "FAMI_EDUCA_MADRE                                       7   \n",
       "FAMI_OCUPA_PADRE                                      04   \n",
       "FAMI_OCUPA_MADRE                                      04   \n",
       "FAMI_NUM_HERMANOS                                      1   \n",
       "FAMI_NUM_HERMANOS_EDUSUPERIOR                          1   \n",
       "FAMI_POSICION_HERMANOS                                 2   \n",
       "FAMI_SOST_PERSONAL                                     T   \n",
       "ESTU_TRABAJA                                           N   \n",
       "ESTU_ACT_PROX_ANNO                                     1   \n",
       "COLE_CALENDARIO                                        A   \n",
       "COLE_BILINGUE                                        NaN   \n",
       "COLE_CARACTER                                  ACADEMICO   \n",
       "COLE_DEPTO_UBICACION                           ANTIOQUIA   \n",
       "COLE_MCPIO_UBICACION                            MEDELLIN   \n",
       "ESTU_TIPO_DOCUMENTO                                    T   \n",
       "ESTU_RESIDE_DEPTO                              ANTIOQUIA   \n",
       "ESTU_RESIDE_MCPIO                               MEDELLIN   \n",
       "\n",
       "                                                                 2  \n",
       "ESTU_CONSECUTIVO                                  SB11200020155853  \n",
       "COLE_COD_ICFES                                               56820  \n",
       "COLE_NOMBRE_SEDE               INSTITUTO TECNOLOGICO METROPOLITANO  \n",
       "IND_ANNO_TERMINO_BACHILLERATO                                 2000  \n",
       "COLE_JORNADA                                                     N  \n",
       "COLE_VALOR_PENSION                                               1  \n",
       "ESTU_GENERO                                                      F  \n",
       "ESTU_NACIMIENTO_DIA                                              3  \n",
       "ESTU_NACIMIENTO_MES                                              1  \n",
       "ESTU_NACIMIENTO_ANNO                                          1978  \n",
       "ESTU_DEPTO_PRESENTACION                                  ANTIOQUIA  \n",
       "ESTU_MCPIO_PRESENTACION                                   MEDELLIN  \n",
       "ESTU_ETNIA                                                     NaN  \n",
       "ESTU_LIMITA_INVIDENTE                                          NaN  \n",
       "ESTU_LIMITA_SORDOINTERPRETE                                    NaN  \n",
       "ESTU_LIMITA_SORDONOINTERPRETE                                  NaN  \n",
       "ESTU_LIMITA_MOTRIZ                                             NaN  \n",
       "PUNT_BIOLOGIA                                                   42  \n",
       "PUNT_MATEMATICAS                                                40  \n",
       "PUNT_FILOSOFIA                                                  53  \n",
       "PUNT_FISICA                                                     44  \n",
       "PUNT_HISTORIA                                                   46  \n",
       "PUNT_QUIMICA                                                    42  \n",
       "PUNT_LENGUAJE                                                   43  \n",
       "PUNT_GEOGRAFIA                                                  45  \n",
       "COD_INTERDISCIPLINAR                                            43  \n",
       "PUNT_INTERDISCIPLINAR                                           44  \n",
       "COD_IDIOMA                                                      51  \n",
       "PUNT_IDIOMA                                                     43  \n",
       "ESTU_IES_COD_DESEADA                                          1201  \n",
       "ESTU_RAZONINSTITUTO                                              3  \n",
       "ESTU_CARRDESEADA_COD                                         12136  \n",
       "ESTU_CARRDESEADA_RAZON                                           5  \n",
       "FAMI_PERSONAS_HOGAR                                              6  \n",
       "FAMI_VIVIENDA_PROPIA                                             S  \n",
       "FAMI_DEUDA_VIVIENDA                                              N  \n",
       "FAMI_APORTANTES                                                  1  \n",
       "FAMI_INGRESO_FMILIAR_MENSUAL                                     1  \n",
       "FAMI_LEE_ESCRIBE_PADRE                                           S  \n",
       "FAMI_LEE_ESCRIBE_MADRE                                           S  \n",
       "FAMI_EDUCA_PADRE                                                 3  \n",
       "FAMI_EDUCA_MADRE                                                 3  \n",
       "FAMI_OCUPA_PADRE                                                08  \n",
       "FAMI_OCUPA_MADRE                                                10  \n",
       "FAMI_NUM_HERMANOS                                                2  \n",
       "FAMI_NUM_HERMANOS_EDUSUPERIOR                                    1  \n",
       "FAMI_POSICION_HERMANOS                                           1  \n",
       "FAMI_SOST_PERSONAL                                               T  \n",
       "ESTU_TRABAJA                                                     N  \n",
       "ESTU_ACT_PROX_ANNO                                               3  \n",
       "COLE_CALENDARIO                                                  F  \n",
       "COLE_BILINGUE                                                  NaN  \n",
       "COLE_CARACTER                                  ACADEMICO Y TECNICO  \n",
       "COLE_DEPTO_UBICACION                                     ANTIOQUIA  \n",
       "COLE_MCPIO_UBICACION                                      MEDELLIN  \n",
       "ESTU_TIPO_DOCUMENTO                                              C  \n",
       "ESTU_RESIDE_DEPTO                                        ANTIOQUIA  \n",
       "ESTU_RESIDE_MCPIO                                         MEDELLIN  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_2000_2.head(3).T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first thing i want to do is delete the columns that does not contribute to the task"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The columns that does not contribute to the task are:\n",
    "- ESTU_CONSECUTIVO\n",
    "- COLE_NOMBRE_SEDE\n",
    "- ESTU_TIPO_DOCUMENTO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data_2000_2 = data_2000_2.drop(['ESTU_CONSECUTIVO', 'COLE_NOMBRE_SEDE', 'ESTU_TIPO_DOCUMENTO'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now i can check the other columns to delete the lines that has strange characters and to decide what to do with the NaN values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['COLE_COD_ICFES', 'IND_ANNO_TERMINO_BACHILLERATO', 'COLE_JORNADA',\n",
       "       'COLE_VALOR_PENSION', 'ESTU_GENERO', 'ESTU_NACIMIENTO_DIA',\n",
       "       'ESTU_NACIMIENTO_MES', 'ESTU_NACIMIENTO_ANNO',\n",
       "       'ESTU_DEPTO_PRESENTACION', 'ESTU_MCPIO_PRESENTACION', 'ESTU_ETNIA',\n",
       "       'ESTU_LIMITA_INVIDENTE', 'ESTU_LIMITA_SORDOINTERPRETE',\n",
       "       'ESTU_LIMITA_SORDONOINTERPRETE', 'ESTU_LIMITA_MOTRIZ', 'PUNT_BIOLOGIA',\n",
       "       'PUNT_MATEMATICAS', 'PUNT_FILOSOFIA', 'PUNT_FISICA', 'PUNT_HISTORIA',\n",
       "       'PUNT_QUIMICA', 'PUNT_LENGUAJE', 'PUNT_GEOGRAFIA',\n",
       "       'COD_INTERDISCIPLINAR', 'PUNT_INTERDISCIPLINAR', 'COD_IDIOMA',\n",
       "       'PUNT_IDIOMA', 'ESTU_IES_COD_DESEADA', 'ESTU_RAZONINSTITUTO',\n",
       "       'ESTU_CARRDESEADA_COD', 'ESTU_CARRDESEADA_RAZON', 'FAMI_PERSONAS_HOGAR',\n",
       "       'FAMI_VIVIENDA_PROPIA', 'FAMI_DEUDA_VIVIENDA', 'FAMI_APORTANTES',\n",
       "       'FAMI_INGRESO_FMILIAR_MENSUAL', 'FAMI_LEE_ESCRIBE_PADRE',\n",
       "       'FAMI_LEE_ESCRIBE_MADRE', 'FAMI_EDUCA_PADRE', 'FAMI_EDUCA_MADRE',\n",
       "       'FAMI_OCUPA_PADRE', 'FAMI_OCUPA_MADRE', 'FAMI_NUM_HERMANOS',\n",
       "       'FAMI_NUM_HERMANOS_EDUSUPERIOR', 'FAMI_POSICION_HERMANOS',\n",
       "       'FAMI_SOST_PERSONAL', 'ESTU_TRABAJA', 'ESTU_ACT_PROX_ANNO',\n",
       "       'COLE_CALENDARIO', 'COLE_BILINGUE', 'COLE_CARACTER',\n",
       "       'COLE_DEPTO_UBICACION', 'COLE_MCPIO_UBICACION', 'ESTU_RESIDE_DEPTO',\n",
       "       'ESTU_RESIDE_MCPIO'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_2000_2.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Float64Index([   18.0,    59.0,    75.0,    83.0,    91.0,   117.0,   125.0,\n",
      "                141.0,   158.0,   174.0,\n",
      "              ...\n",
      "              93740.0, 93757.0, 93765.0, 93773.0, 93781.0, 93799.0, 93807.0,\n",
      "              93815.0, 93823.0, 93831.0],\n",
      "             dtype='float64', length=6573)\n",
      "18.0        22\n",
      "59.0       913\n",
      "75.0        51\n",
      "83.0        56\n",
      "91.0       133\n",
      "117.0       38\n",
      "125.0      102\n",
      "141.0       81\n",
      "158.0       40\n",
      "174.0      107\n",
      "190.0       55\n",
      "208.0      108\n",
      "216.0       33\n",
      "232.0       31\n",
      "240.0      197\n",
      "257.0      109\n",
      "265.0      697\n",
      "273.0       90\n",
      "281.0       74\n",
      "315.0      180\n",
      "349.0       12\n",
      "356.0       32\n",
      "364.0       78\n",
      "372.0       68\n",
      "380.0      234\n",
      "398.0       42\n",
      "406.0       60\n",
      "422.0       33\n",
      "430.0       88\n",
      "448.0       25\n",
      "          ... \n",
      "93542.0     20\n",
      "93559.0     22\n",
      "93567.0     31\n",
      "93575.0      5\n",
      "93583.0     39\n",
      "93591.0     53\n",
      "93609.0     13\n",
      "93617.0     18\n",
      "93625.0     26\n",
      "93633.0     10\n",
      "93641.0     19\n",
      "93658.0     15\n",
      "93666.0     39\n",
      "93674.0     32\n",
      "93682.0     14\n",
      "93690.0      2\n",
      "93708.0     11\n",
      "93716.0     68\n",
      "93724.0      4\n",
      "93732.0     16\n",
      "93740.0     15\n",
      "93757.0      9\n",
      "93765.0     36\n",
      "93773.0     17\n",
      "93781.0     10\n",
      "93799.0     36\n",
      "93807.0     40\n",
      "93815.0     31\n",
      "93823.0     18\n",
      "93831.0     58\n",
      "Name: COLE_COD_ICFES, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "\"\"\"It looks like a good columns, type: float64\"\"\"\n",
    "print(data_2000_2['COLE_COD_ICFES'].value_counts().sort_index().index)\n",
    "print(data_2000_2['COLE_COD_ICFES'].value_counts().sort_index())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['1959', '1979', '1980', '1981', '1982', '1983', '1984', '1987', '1988',\n",
      "       '1989', '1991', '1992', '1993', '1994', '1995', '1996', '1997', '1998',\n",
      "       '1999', '2', '2  0', '2  1', '2 *0', '2 0', '2 00', '2*00', '20',\n",
      "       '20 *', '20 0', '20 1', '20*', '20**', '20*0', '200', '200*', '2000',\n",
      "       '2001', '2002', '2006', '201', '2010', '2011', '2020', '2022', '2030',\n",
      "       '2060', '2099'],\n",
      "      dtype='object')\n",
      "1959         1\n",
      "1979         1\n",
      "1980         1\n",
      "1981         1\n",
      "1982         1\n",
      "1983         1\n",
      "1984         1\n",
      "1987         1\n",
      "1988         1\n",
      "1989         3\n",
      "1991         2\n",
      "1992         1\n",
      "1993         2\n",
      "1994         1\n",
      "1995         4\n",
      "1996         6\n",
      "1997         7\n",
      "1998        20\n",
      "1999       226\n",
      "2           74\n",
      "2  0        58\n",
      "2  1         1\n",
      "2 *0         1\n",
      "2 0         30\n",
      "2 00      1140\n",
      "2*00         4\n",
      "20         152\n",
      "20 *         2\n",
      "20 0       458\n",
      "20 1         1\n",
      "20*          2\n",
      "20**         5\n",
      "20*0         7\n",
      "200        306\n",
      "200*         2\n",
      "2000    352083\n",
      "2001       122\n",
      "2002         3\n",
      "2006         1\n",
      "201          2\n",
      "2010        16\n",
      "2011        36\n",
      "2020         1\n",
      "2022         1\n",
      "2030         1\n",
      "2060         1\n",
      "2099         2\n",
      "Name: IND_ANNO_TERMINO_BACHILLERATO, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "\"\"\"There are some years that are not valid, so this lines will be deleted\"\"\"\n",
    "print(data_2000_2['IND_ANNO_TERMINO_BACHILLERATO'].value_counts().sort_index().index)\n",
    "print(data_2000_2['IND_ANNO_TERMINO_BACHILLERATO'].value_counts().sort_index())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data_2000_2 = drop_lines(data_2000_2, 'IND_ANNO_TERMINO_BACHILLERATO', '201')\n",
    "data_2000_2 = drop_lines(data_2000_2, 'IND_ANNO_TERMINO_BACHILLERATO', '2')\n",
    "data_2000_2 = drop_lines(data_2000_2, 'IND_ANNO_TERMINO_BACHILLERATO', '2  0')\n",
    "data_2000_2 = drop_lines(data_2000_2, 'IND_ANNO_TERMINO_BACHILLERATO', '2  1')\n",
    "data_2000_2 = drop_lines(data_2000_2, 'IND_ANNO_TERMINO_BACHILLERATO', '2 *0')\n",
    "data_2000_2 = drop_lines(data_2000_2, 'IND_ANNO_TERMINO_BACHILLERATO', '2 0')\n",
    "data_2000_2 = drop_lines(data_2000_2, 'IND_ANNO_TERMINO_BACHILLERATO', '2 00')\n",
    "data_2000_2 = drop_lines(data_2000_2, 'IND_ANNO_TERMINO_BACHILLERATO', '2*00')\n",
    "data_2000_2 = drop_lines(data_2000_2, 'IND_ANNO_TERMINO_BACHILLERATO', '20')\n",
    "data_2000_2 = drop_lines(data_2000_2, 'IND_ANNO_TERMINO_BACHILLERATO', '20 *')\n",
    "data_2000_2 = drop_lines(data_2000_2, 'IND_ANNO_TERMINO_BACHILLERATO', '20 0')\n",
    "data_2000_2 = drop_lines(data_2000_2, 'IND_ANNO_TERMINO_BACHILLERATO', '20 1')\n",
    "data_2000_2 = drop_lines(data_2000_2, 'IND_ANNO_TERMINO_BACHILLERATO', '20*')\n",
    "data_2000_2 = drop_lines(data_2000_2, 'IND_ANNO_TERMINO_BACHILLERATO', '20**')\n",
    "data_2000_2 = drop_lines(data_2000_2, 'IND_ANNO_TERMINO_BACHILLERATO', '20*0')\n",
    "data_2000_2 = drop_lines(data_2000_2, 'IND_ANNO_TERMINO_BACHILLERATO', '200')\n",
    "data_2000_2 = drop_lines(data_2000_2, 'IND_ANNO_TERMINO_BACHILLERATO', '200*')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['C', 'M', 'N', 'S', 'T'], dtype='object')\n",
      "C     82291\n",
      "M    146632\n",
      "N     46800\n",
      "S       449\n",
      "T     76445\n",
      "Name: COLE_JORNADA, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "\"\"\"This columns looks good\"\"\"\n",
    "print(data_2000_2['COLE_JORNADA'].value_counts().sort_index().index)\n",
    "print(data_2000_2['COLE_JORNADA'].value_counts().sort_index())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elementos null/NaN 19526\n",
      "__________________\n",
      "Elementos diferentes de null/NaN: 335336\n",
      "__________________\n",
      "(335336,)\n"
     ]
    }
   ],
   "source": [
    "\"\"\"Obtained an error, a this happens because of the NaN values, i decide to do a first treatment, just deleting the \n",
    "data. Then in another time i can find another way to treat this NaN values. This almost 20000 lines just represent \n",
    "a 5% of the data\"\"\"\n",
    "#print(data_2000_2['COLE_VALOR_PENSION'].value_counts().sort_index().index)\n",
    "#print(data_2000_2['COLE_VALOR_PENSION'].value_counts().sort_index())\n",
    "missing_data(data_2000_2['COLE_VALOR_PENSION'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\"\"\"Deleting the lines that has de NaN value in the columns COLE_VALOR_PENSION\"\"\"\n",
    "data_2000_2.drop(data_2000_2[data_2000_2['COLE_VALOR_PENSION'].isnull()].index, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"Checking if that worked\"\"\"\n",
    "data_2000_2['COLE_VALOR_PENSION'].isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    139638\n",
       "8     90846\n",
       "2     30933\n",
       "3     24311\n",
       "4     20139\n",
       "5     15875\n",
       "6     10469\n",
       "7      3097\n",
       "Name: COLE_VALOR_PENSION, dtype: int64"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_2000_2['COLE_VALOR_PENSION'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HERE IS HAPPENING SOMETHING STRANGE PLEASE FIX IT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"So now, i can replace the duplicates written as floats. I insert the string values corresponding to each number\"\"\"\n",
    "data_2000_2['COLE_VALOR_PENSION'] = data_2000_2['COLE_VALOR_PENSION'].replace(1.0, 1)\n",
    "data_2000_2['COLE_VALOR_PENSION'] = data_2000_2['COLE_VALOR_PENSION'].replace(8.0, 8)\n",
    "data_2000_2['COLE_VALOR_PENSION'] = data_2000_2['COLE_VALOR_PENSION'].replace(2.0, 2)\n",
    "data_2000_2['COLE_VALOR_PENSION'] = data_2000_2['COLE_VALOR_PENSION'].replace(3.0, 3)\n",
    "data_2000_2['COLE_VALOR_PENSION'] = data_2000_2['COLE_VALOR_PENSION'].replace(4.0, 4)\n",
    "data_2000_2['COLE_VALOR_PENSION'] = data_2000_2['COLE_VALOR_PENSION'].replace(5.0, 5)\n",
    "data_2000_2['COLE_VALOR_PENSION'] = data_2000_2['COLE_VALOR_PENSION'].replace(6.0, 6)\n",
    "data_2000_2['COLE_VALOR_PENSION'] = data_2000_2['COLE_VALOR_PENSION'].replace(7.0, 7)\n",
    "\"\"\"Now i can replace the number type values, for string type values.\"\"\"\n",
    "data_2000_2['COLE_VALOR_PENSION'] = data_2000_2['COLE_VALOR_PENSION'].replace(1, '1')\n",
    "data_2000_2['COLE_VALOR_PENSION'] = data_2000_2['COLE_VALOR_PENSION'].replace(2, '2')\n",
    "data_2000_2['COLE_VALOR_PENSION'] = data_2000_2['COLE_VALOR_PENSION'].replace(3, '3')\n",
    "data_2000_2['COLE_VALOR_PENSION'] = data_2000_2['COLE_VALOR_PENSION'].replace(4, '4')\n",
    "data_2000_2['COLE_VALOR_PENSION'] = data_2000_2['COLE_VALOR_PENSION'].replace(5, '5')\n",
    "data_2000_2['COLE_VALOR_PENSION'] = data_2000_2['COLE_VALOR_PENSION'].replace(6, '6')\n",
    "data_2000_2['COLE_VALOR_PENSION'] = data_2000_2['COLE_VALOR_PENSION'].replace(7, '7')\n",
    "data_2000_2['COLE_VALOR_PENSION'] = data_2000_2['COLE_VALOR_PENSION'].replace(8, '8')\n",
    "\"\"\"Now the files with the '*' value are deleted\"\"\"\n",
    "data_2000_2 = drop_lines(data_2000_2, 'COLE_VALOR_PENSION', '*')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['1', '2', '3', '4', '5', '6', '7', '8'], dtype='object')\n",
      "1    139638\n",
      "2     30933\n",
      "3     24311\n",
      "4     20139\n",
      "5     15875\n",
      "6     10469\n",
      "7      3097\n",
      "8     90846\n",
      "Name: COLE_VALOR_PENSION, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(data_2000_2['COLE_VALOR_PENSION'].value_counts().sort_index().index)\n",
    "print(data_2000_2['COLE_VALOR_PENSION'].value_counts().sort_index())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['F', 'M'], dtype='object')\n",
      "F    181432\n",
      "M    153876\n",
      "Name: ESTU_GENERO, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "\"\"\"This column is ok\"\"\"\n",
    "print(data_2000_2['ESTU_GENERO'].value_counts().sort_index().index)\n",
    "print(data_2000_2['ESTU_GENERO'].value_counts().sort_index())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elementos null/NaN 268\n",
      "__________________\n",
      "Elementos diferentes de null/NaN: 335040\n",
      "__________________\n",
      "(335040,)\n"
     ]
    }
   ],
   "source": [
    "\"\"\"I get errors with this column\"\"\"\n",
    "#print(data_2000_2['ESTU_NACIMIENTO_DIA'].value_counts().sort_index().index)\n",
    "#print(data_2000_2['ESTU_NACIMIENTO_DIA'].value_counts().sort_index())\n",
    "missing_data(data_2000_2['ESTU_NACIMIENTO_DIA'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"how there is just 268 lines with NaN values, i decide to delete them\"\"\"\n",
    "data_2000_2.drop(data_2000_2[data_2000_2['ESTU_NACIMIENTO_DIA'].isnull()].index, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['01', '20', '05', '10', '03', '28', '15', '18', '12', '07', '04', '06',\n",
      "       '23', '08', '02', '17', '11', '26', '25', '22', '16', '14', '24', '09',\n",
      "       '27', '13', '19', '21', '29', '30', '31',  1.0,  5.0,  3.0, 15.0, 10.0,\n",
      "        6.0, 20.0, 25.0, 12.0,  2.0,  8.0,  7.0, 27.0, 28.0, 16.0, 17.0,  9.0,\n",
      "       11.0,  4.0, 18.0, 23.0, 14.0, 19.0, 22.0, 24.0, 26.0, 13.0, 21.0, 29.0,\n",
      "       30.0, 31.0,  '1',  '2',  '3',  '*', '1*',  '0',  '4',  '8',  '7', '2*',\n",
      "        0.0,  '5',  '9',  '6', '00', '*1', '39', '0*', '*9', '32'],\n",
      "      dtype='object')\n",
      "01      8389\n",
      "20      8346\n",
      "05      8321\n",
      "10      8318\n",
      "03      8245\n",
      "28      8219\n",
      "15      8162\n",
      "18      8112\n",
      "12      8056\n",
      "07      8054\n",
      "04      8043\n",
      "06      8036\n",
      "23      8028\n",
      "08      8021\n",
      "02      8012\n",
      "17      7988\n",
      "11      7982\n",
      "26      7953\n",
      "25      7932\n",
      "22      7893\n",
      "16      7893\n",
      "14      7865\n",
      "24      7842\n",
      "09      7835\n",
      "27      7835\n",
      "13      7735\n",
      "19      7692\n",
      "21      7632\n",
      "29      7446\n",
      "30      7288\n",
      "        ... \n",
      "14.0    2951\n",
      "19.0    2935\n",
      "22.0    2930\n",
      "24.0    2918\n",
      "26.0    2878\n",
      "13.0    2854\n",
      "21.0    2825\n",
      "29.0    2792\n",
      "30.0    2721\n",
      "31.0    1622\n",
      "1        206\n",
      "2        186\n",
      "3         43\n",
      "*         23\n",
      "1*        14\n",
      "0         13\n",
      "4          9\n",
      "8          8\n",
      "7          6\n",
      "2*         6\n",
      "0.0        6\n",
      "5          5\n",
      "9          4\n",
      "6          2\n",
      "00         2\n",
      "*1         1\n",
      "39         1\n",
      "0*         1\n",
      "*9         1\n",
      "32         1\n",
      "Name: ESTU_NACIMIENTO_DIA, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(data_2000_2['ESTU_NACIMIENTO_DIA'].value_counts().index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"With the NaN values deleted, there is some lines that has to be erased\"\"\"\n",
    "data_2000_2 = drop_lines(data_2000_2, 'ESTU_NACIMIENTO_DIA', '*')\n",
    "data_2000_2 = drop_lines(data_2000_2, 'ESTU_NACIMIENTO_DIA', '1*')\n",
    "data_2000_2 = drop_lines(data_2000_2, 'ESTU_NACIMIENTO_DIA', '0')\n",
    "data_2000_2 = drop_lines(data_2000_2, 'ESTU_NACIMIENTO_DIA', '2*')\n",
    "data_2000_2 = drop_lines(data_2000_2, 'ESTU_NACIMIENTO_DIA', 0.0)\n",
    "data_2000_2 = drop_lines(data_2000_2, 'ESTU_NACIMIENTO_DIA', '00')\n",
    "data_2000_2 = drop_lines(data_2000_2, 'ESTU_NACIMIENTO_DIA', '*1')\n",
    "data_2000_2 = drop_lines(data_2000_2, 'ESTU_NACIMIENTO_DIA', '0*')\n",
    "data_2000_2 = drop_lines(data_2000_2, 'ESTU_NACIMIENTO_DIA', '*9')\n",
    "data_2000_2 = drop_lines(data_2000_2, 'ESTU_NACIMIENTO_DIA', '32')\n",
    "data_2000_2 = drop_lines(data_2000_2, 'ESTU_NACIMIENTO_DIA', '39')\n",
    "\n",
    "\"\"\"Now it's time to replace the number values for string values\"\"\"\n",
    "data_2000_2['ESTU_NACIMIENTO_DIA'] = data_2000_2['ESTU_NACIMIENTO_DIA'].replace(1.0, 1)\n",
    "data_2000_2['ESTU_NACIMIENTO_DIA'] = data_2000_2['ESTU_NACIMIENTO_DIA'].replace(2.0, 2)\n",
    "data_2000_2['ESTU_NACIMIENTO_DIA'] = data_2000_2['ESTU_NACIMIENTO_DIA'].replace(3.0, 3)\n",
    "data_2000_2['ESTU_NACIMIENTO_DIA'] = data_2000_2['ESTU_NACIMIENTO_DIA'].replace(4.0, 4)\n",
    "data_2000_2['ESTU_NACIMIENTO_DIA'] = data_2000_2['ESTU_NACIMIENTO_DIA'].replace(5.0, 5)\n",
    "data_2000_2['ESTU_NACIMIENTO_DIA'] = data_2000_2['ESTU_NACIMIENTO_DIA'].replace(6.0, 6)\n",
    "data_2000_2['ESTU_NACIMIENTO_DIA'] = data_2000_2['ESTU_NACIMIENTO_DIA'].replace(7.0, 7)\n",
    "data_2000_2['ESTU_NACIMIENTO_DIA'] = data_2000_2['ESTU_NACIMIENTO_DIA'].replace(8.0, 8)\n",
    "data_2000_2['ESTU_NACIMIENTO_DIA'] = data_2000_2['ESTU_NACIMIENTO_DIA'].replace(9.0, 9)\n",
    "data_2000_2['ESTU_NACIMIENTO_DIA'] = data_2000_2['ESTU_NACIMIENTO_DIA'].replace(10.0, 10)\n",
    "data_2000_2['ESTU_NACIMIENTO_DIA'] = data_2000_2['ESTU_NACIMIENTO_DIA'].replace(11.0, 11)\n",
    "data_2000_2['ESTU_NACIMIENTO_DIA'] = data_2000_2['ESTU_NACIMIENTO_DIA'].replace(12.0, 12)\n",
    "data_2000_2['ESTU_NACIMIENTO_DIA'] = data_2000_2['ESTU_NACIMIENTO_DIA'].replace(13.0, 13)\n",
    "data_2000_2['ESTU_NACIMIENTO_DIA'] = data_2000_2['ESTU_NACIMIENTO_DIA'].replace(14.0, 14)\n",
    "data_2000_2['ESTU_NACIMIENTO_DIA'] = data_2000_2['ESTU_NACIMIENTO_DIA'].replace(15.0, 15)\n",
    "data_2000_2['ESTU_NACIMIENTO_DIA'] = data_2000_2['ESTU_NACIMIENTO_DIA'].replace(16.0, 16)\n",
    "data_2000_2['ESTU_NACIMIENTO_DIA'] = data_2000_2['ESTU_NACIMIENTO_DIA'].replace(17.0, 17)\n",
    "data_2000_2['ESTU_NACIMIENTO_DIA'] = data_2000_2['ESTU_NACIMIENTO_DIA'].replace(18.0, 18)\n",
    "data_2000_2['ESTU_NACIMIENTO_DIA'] = data_2000_2['ESTU_NACIMIENTO_DIA'].replace(19.0, 19)\n",
    "data_2000_2['ESTU_NACIMIENTO_DIA'] = data_2000_2['ESTU_NACIMIENTO_DIA'].replace(20.0, 20)\n",
    "data_2000_2['ESTU_NACIMIENTO_DIA'] = data_2000_2['ESTU_NACIMIENTO_DIA'].replace(21.0, 21)\n",
    "data_2000_2['ESTU_NACIMIENTO_DIA'] = data_2000_2['ESTU_NACIMIENTO_DIA'].replace(22.0, 22)\n",
    "data_2000_2['ESTU_NACIMIENTO_DIA'] = data_2000_2['ESTU_NACIMIENTO_DIA'].replace(23.0, 23)\n",
    "data_2000_2['ESTU_NACIMIENTO_DIA'] = data_2000_2['ESTU_NACIMIENTO_DIA'].replace(24.0, 24)\n",
    "data_2000_2['ESTU_NACIMIENTO_DIA'] = data_2000_2['ESTU_NACIMIENTO_DIA'].replace(25.0, 25)\n",
    "data_2000_2['ESTU_NACIMIENTO_DIA'] = data_2000_2['ESTU_NACIMIENTO_DIA'].replace(26.0, 26)\n",
    "data_2000_2['ESTU_NACIMIENTO_DIA'] = data_2000_2['ESTU_NACIMIENTO_DIA'].replace(27.0, 27)\n",
    "data_2000_2['ESTU_NACIMIENTO_DIA'] = data_2000_2['ESTU_NACIMIENTO_DIA'].replace(28.0, 28)\n",
    "data_2000_2['ESTU_NACIMIENTO_DIA'] = data_2000_2['ESTU_NACIMIENTO_DIA'].replace(29.0, 29)\n",
    "data_2000_2['ESTU_NACIMIENTO_DIA'] = data_2000_2['ESTU_NACIMIENTO_DIA'].replace(30.0, 30)\n",
    "data_2000_2['ESTU_NACIMIENTO_DIA'] = data_2000_2['ESTU_NACIMIENTO_DIA'].replace(31.0, 31)\n",
    "\n",
    "\"\"\"Now i change this values to a string type\"\"\"\n",
    "data_2000_2['ESTU_NACIMIENTO_DIA'] = data_2000_2['ESTU_NACIMIENTO_DIA'].replace(1, '1')\n",
    "data_2000_2['ESTU_NACIMIENTO_DIA'] = data_2000_2['ESTU_NACIMIENTO_DIA'].replace(2, '2')\n",
    "data_2000_2['ESTU_NACIMIENTO_DIA'] = data_2000_2['ESTU_NACIMIENTO_DIA'].replace(3, '3')\n",
    "data_2000_2['ESTU_NACIMIENTO_DIA'] = data_2000_2['ESTU_NACIMIENTO_DIA'].replace(4, '4')\n",
    "data_2000_2['ESTU_NACIMIENTO_DIA'] = data_2000_2['ESTU_NACIMIENTO_DIA'].replace(5, '5')\n",
    "data_2000_2['ESTU_NACIMIENTO_DIA'] = data_2000_2['ESTU_NACIMIENTO_DIA'].replace(6, '6')\n",
    "data_2000_2['ESTU_NACIMIENTO_DIA'] = data_2000_2['ESTU_NACIMIENTO_DIA'].replace(7, '7')\n",
    "data_2000_2['ESTU_NACIMIENTO_DIA'] = data_2000_2['ESTU_NACIMIENTO_DIA'].replace(8, '8')\n",
    "data_2000_2['ESTU_NACIMIENTO_DIA'] = data_2000_2['ESTU_NACIMIENTO_DIA'].replace(9, '9')\n",
    "data_2000_2['ESTU_NACIMIENTO_DIA'] = data_2000_2['ESTU_NACIMIENTO_DIA'].replace(10, '10')\n",
    "data_2000_2['ESTU_NACIMIENTO_DIA'] = data_2000_2['ESTU_NACIMIENTO_DIA'].replace(11, '11')\n",
    "data_2000_2['ESTU_NACIMIENTO_DIA'] = data_2000_2['ESTU_NACIMIENTO_DIA'].replace(12, '12')\n",
    "data_2000_2['ESTU_NACIMIENTO_DIA'] = data_2000_2['ESTU_NACIMIENTO_DIA'].replace(13, '13')\n",
    "data_2000_2['ESTU_NACIMIENTO_DIA'] = data_2000_2['ESTU_NACIMIENTO_DIA'].replace(14, '14')\n",
    "data_2000_2['ESTU_NACIMIENTO_DIA'] = data_2000_2['ESTU_NACIMIENTO_DIA'].replace(15, '15')\n",
    "data_2000_2['ESTU_NACIMIENTO_DIA'] = data_2000_2['ESTU_NACIMIENTO_DIA'].replace(16, '16')\n",
    "data_2000_2['ESTU_NACIMIENTO_DIA'] = data_2000_2['ESTU_NACIMIENTO_DIA'].replace(17, '17')\n",
    "data_2000_2['ESTU_NACIMIENTO_DIA'] = data_2000_2['ESTU_NACIMIENTO_DIA'].replace(18, '18')\n",
    "data_2000_2['ESTU_NACIMIENTO_DIA'] = data_2000_2['ESTU_NACIMIENTO_DIA'].replace(19, '19')\n",
    "data_2000_2['ESTU_NACIMIENTO_DIA'] = data_2000_2['ESTU_NACIMIENTO_DIA'].replace(20, '20')\n",
    "data_2000_2['ESTU_NACIMIENTO_DIA'] = data_2000_2['ESTU_NACIMIENTO_DIA'].replace(21, '21')\n",
    "data_2000_2['ESTU_NACIMIENTO_DIA'] = data_2000_2['ESTU_NACIMIENTO_DIA'].replace(22, '22')\n",
    "data_2000_2['ESTU_NACIMIENTO_DIA'] = data_2000_2['ESTU_NACIMIENTO_DIA'].replace(23, '23')\n",
    "data_2000_2['ESTU_NACIMIENTO_DIA'] = data_2000_2['ESTU_NACIMIENTO_DIA'].replace(24, '24')\n",
    "data_2000_2['ESTU_NACIMIENTO_DIA'] = data_2000_2['ESTU_NACIMIENTO_DIA'].replace(25, '25')\n",
    "data_2000_2['ESTU_NACIMIENTO_DIA'] = data_2000_2['ESTU_NACIMIENTO_DIA'].replace(26, '26')\n",
    "data_2000_2['ESTU_NACIMIENTO_DIA'] = data_2000_2['ESTU_NACIMIENTO_DIA'].replace(27, '27')\n",
    "data_2000_2['ESTU_NACIMIENTO_DIA'] = data_2000_2['ESTU_NACIMIENTO_DIA'].replace(28, '28')\n",
    "data_2000_2['ESTU_NACIMIENTO_DIA'] = data_2000_2['ESTU_NACIMIENTO_DIA'].replace(29, '29')\n",
    "data_2000_2['ESTU_NACIMIENTO_DIA'] = data_2000_2['ESTU_NACIMIENTO_DIA'].replace(30, '30')\n",
    "data_2000_2['ESTU_NACIMIENTO_DIA'] = data_2000_2['ESTU_NACIMIENTO_DIA'].replace(31, '31')\n",
    "\n",
    "\"\"\"And Finally a change some values to left everything in just one way\"\"\"\n",
    "data_2000_2['ESTU_NACIMIENTO_DIA'] = data_2000_2['ESTU_NACIMIENTO_DIA'].replace('01', '1')\n",
    "data_2000_2['ESTU_NACIMIENTO_DIA'] = data_2000_2['ESTU_NACIMIENTO_DIA'].replace('05', '5')\n",
    "data_2000_2['ESTU_NACIMIENTO_DIA'] = data_2000_2['ESTU_NACIMIENTO_DIA'].replace('03', '3')\n",
    "data_2000_2['ESTU_NACIMIENTO_DIA'] = data_2000_2['ESTU_NACIMIENTO_DIA'].replace('07', '7')\n",
    "data_2000_2['ESTU_NACIMIENTO_DIA'] = data_2000_2['ESTU_NACIMIENTO_DIA'].replace('04', '4')\n",
    "data_2000_2['ESTU_NACIMIENTO_DIA'] = data_2000_2['ESTU_NACIMIENTO_DIA'].replace('06', '6')\n",
    "data_2000_2['ESTU_NACIMIENTO_DIA'] = data_2000_2['ESTU_NACIMIENTO_DIA'].replace('08', '8')\n",
    "data_2000_2['ESTU_NACIMIENTO_DIA'] = data_2000_2['ESTU_NACIMIENTO_DIA'].replace('02', '2')\n",
    "data_2000_2['ESTU_NACIMIENTO_DIA'] = data_2000_2['ESTU_NACIMIENTO_DIA'].replace('09', '9')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['1', '10', '11', '12', '13', '14', '15', '16', '17', '18', '19', '2',\n",
      "       '20', '21', '22', '23', '24', '25', '26', '27', '28', '29', '3', '30',\n",
      "       '31', '4', '5', '6', '7', '8', '9'],\n",
      "      dtype='object')\n",
      "1     11831\n",
      "5     11502\n",
      "20    11387\n",
      "3     11367\n",
      "10    11364\n",
      "2     11217\n",
      "15    11216\n",
      "28    11213\n",
      "6     11083\n",
      "12    11077\n",
      "18    11075\n",
      "7     11068\n",
      "8     11041\n",
      "4     11017\n",
      "23    10980\n",
      "17    10978\n",
      "25    10961\n",
      "11    10948\n",
      "16    10884\n",
      "27    10837\n",
      "26    10831\n",
      "22    10823\n",
      "9     10817\n",
      "14    10816\n",
      "24    10760\n",
      "19    10627\n",
      "13    10589\n",
      "21    10457\n",
      "29    10238\n",
      "30    10009\n",
      "31     5958\n",
      "Name: ESTU_NACIMIENTO_DIA, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(data_2000_2['ESTU_NACIMIENTO_DIA'].value_counts().sort_index().index)\n",
    "print(data_2000_2['ESTU_NACIMIENTO_DIA'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Float64Index([1.0, 2.0, 3.0, 4.0, 5.0, 6.0, 7.0, 8.0, 9.0, 10.0, 11.0, 12.0], dtype='float64')\n",
      "1.0     27910\n",
      "2.0     24938\n",
      "3.0     28007\n",
      "4.0     26665\n",
      "5.0     27706\n",
      "6.0     26468\n",
      "7.0     27238\n",
      "8.0     28283\n",
      "9.0     29905\n",
      "10.0    29746\n",
      "11.0    28694\n",
      "12.0    28515\n",
      "Name: ESTU_NACIMIENTO_MES, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "\"\"\"This column is OK\"\"\"\n",
    "print(data_2000_2['ESTU_NACIMIENTO_MES'].value_counts().sort_index().index)\n",
    "print(data_2000_2['ESTU_NACIMIENTO_MES'].value_counts().sort_index())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['*', '**', '*7', '*9', '*972', '0', '0*3', '00', '0973', '098',\n",
      "       ...\n",
      "       '2980', '7', '8', '9', '9 0', '9 2', '9*1', '95', '97', '98'],\n",
      "      dtype='object', length=124)\n",
      "*            3\n",
      "**           5\n",
      "*7           1\n",
      "*9           1\n",
      "*972         1\n",
      "0            2\n",
      "0*3          1\n",
      "00           1\n",
      "0973         1\n",
      "098          1\n",
      "1            2\n",
      "1  0         1\n",
      "1  9         1\n",
      "1 *6         1\n",
      "1 *8         1\n",
      "1 *9         1\n",
      "1 8          1\n",
      "1 9*         5\n",
      "1 96         1\n",
      "1 97         4\n",
      "1*           2\n",
      "1*8          1\n",
      "17           1\n",
      "19          10\n",
      "19 *         8\n",
      "19 0         1\n",
      "19 1         2\n",
      "19 5         1\n",
      "19 6         4\n",
      "19 7        17\n",
      "         ...  \n",
      "1981     38426\n",
      "1982     68871\n",
      "1983    103469\n",
      "1984     60990\n",
      "1985      5461\n",
      "1986       196\n",
      "1987        50\n",
      "1988        53\n",
      "1989        51\n",
      "199          2\n",
      "199*        21\n",
      "1990        19\n",
      "1991         1\n",
      "1996         1\n",
      "1997         3\n",
      "1998         1\n",
      "1999         1\n",
      "2 *7         2\n",
      "2 00         1\n",
      "2000         3\n",
      "2980         1\n",
      "7            1\n",
      "8            2\n",
      "9            3\n",
      "9 0          1\n",
      "9 2          1\n",
      "9*1          1\n",
      "95           1\n",
      "97           1\n",
      "98           3\n",
      "Name: ESTU_NACIMIENTO_ANNO, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "\"\"\"This column present A LOT of incoherences.\"\"\"\n",
    "print(data_2000_2['ESTU_NACIMIENTO_ANNO'].value_counts().sort_index().index)\n",
    "print(data_2000_2['ESTU_NACIMIENTO_ANNO'].value_counts().sort_index())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"All of that incoherences found, will be deleted\"\"\"\n",
    "data_2000_2 = drop_lines(data_2000_2, 'ESTU_NACIMIENTO_ANNO', '*')\n",
    "data_2000_2 = drop_lines(data_2000_2, 'ESTU_NACIMIENTO_ANNO', '**')\n",
    "data_2000_2 = drop_lines(data_2000_2, 'ESTU_NACIMIENTO_ANNO', '*7')\n",
    "data_2000_2 = drop_lines(data_2000_2, 'ESTU_NACIMIENTO_ANNO', '*9')\n",
    "data_2000_2 = drop_lines(data_2000_2, 'ESTU_NACIMIENTO_ANNO', '*972')\n",
    "data_2000_2 = drop_lines(data_2000_2, 'ESTU_NACIMIENTO_ANNO', '0')\n",
    "data_2000_2 = drop_lines(data_2000_2, 'ESTU_NACIMIENTO_ANNO', '0*3')\n",
    "data_2000_2 = drop_lines(data_2000_2, 'ESTU_NACIMIENTO_ANNO', '00')\n",
    "data_2000_2 = drop_lines(data_2000_2, 'ESTU_NACIMIENTO_ANNO', '0973')\n",
    "data_2000_2 = drop_lines(data_2000_2, 'ESTU_NACIMIENTO_ANNO', '098')\n",
    "data_2000_2 = drop_lines(data_2000_2, 'ESTU_NACIMIENTO_ANNO', '1')\n",
    "data_2000_2 = drop_lines(data_2000_2, 'ESTU_NACIMIENTO_ANNO', '1  0')\n",
    "data_2000_2 = drop_lines(data_2000_2, 'ESTU_NACIMIENTO_ANNO', '1  9')\n",
    "data_2000_2 = drop_lines(data_2000_2, 'ESTU_NACIMIENTO_ANNO', '1 *6')\n",
    "data_2000_2 = drop_lines(data_2000_2, 'ESTU_NACIMIENTO_ANNO', '1 *8')\n",
    "data_2000_2 = drop_lines(data_2000_2, 'ESTU_NACIMIENTO_ANNO', '1 *9')\n",
    "data_2000_2 = drop_lines(data_2000_2, 'ESTU_NACIMIENTO_ANNO', '1 8')\n",
    "data_2000_2 = drop_lines(data_2000_2, 'ESTU_NACIMIENTO_ANNO', '1 9*')\n",
    "data_2000_2 = drop_lines(data_2000_2, 'ESTU_NACIMIENTO_ANNO', '1 9*')\n",
    "data_2000_2 = drop_lines(data_2000_2, 'ESTU_NACIMIENTO_ANNO', '1 96')\n",
    "data_2000_2 = drop_lines(data_2000_2, 'ESTU_NACIMIENTO_ANNO', '1 97')\n",
    "data_2000_2 = drop_lines(data_2000_2, 'ESTU_NACIMIENTO_ANNO', '1*')\n",
    "data_2000_2 = drop_lines(data_2000_2, 'ESTU_NACIMIENTO_ANNO', '1*8')\n",
    "data_2000_2 = drop_lines(data_2000_2, 'ESTU_NACIMIENTO_ANNO', '17')\n",
    "data_2000_2 = drop_lines(data_2000_2, 'ESTU_NACIMIENTO_ANNO', '19')\n",
    "data_2000_2 = drop_lines(data_2000_2, 'ESTU_NACIMIENTO_ANNO', '19 *')\n",
    "data_2000_2 = drop_lines(data_2000_2, 'ESTU_NACIMIENTO_ANNO', '19 0')\n",
    "data_2000_2 = drop_lines(data_2000_2, 'ESTU_NACIMIENTO_ANNO', '19 1')\n",
    "data_2000_2 = drop_lines(data_2000_2, 'ESTU_NACIMIENTO_ANNO', '19 5')\n",
    "data_2000_2 = drop_lines(data_2000_2, 'ESTU_NACIMIENTO_ANNO', '19 6')\n",
    "data_2000_2 = drop_lines(data_2000_2, 'ESTU_NACIMIENTO_ANNO', '19 7')\n",
    "data_2000_2 = drop_lines(data_2000_2, 'ESTU_NACIMIENTO_ANNO', '19 8')\n",
    "data_2000_2 = drop_lines(data_2000_2, 'ESTU_NACIMIENTO_ANNO', '19*')\n",
    "data_2000_2 = drop_lines(data_2000_2, 'ESTU_NACIMIENTO_ANNO', '19*0')\n",
    "data_2000_2 = drop_lines(data_2000_2, 'ESTU_NACIMIENTO_ANNO', '19*1')\n",
    "data_2000_2 = drop_lines(data_2000_2, 'ESTU_NACIMIENTO_ANNO', '19*4')\n",
    "data_2000_2 = drop_lines(data_2000_2, 'ESTU_NACIMIENTO_ANNO', '19*8')\n",
    "data_2000_2 = drop_lines(data_2000_2, 'ESTU_NACIMIENTO_ANNO', '191')\n",
    "data_2000_2 = drop_lines(data_2000_2, 'ESTU_NACIMIENTO_ANNO', '194')\n",
    "data_2000_2 = drop_lines(data_2000_2, 'ESTU_NACIMIENTO_ANNO', '195')\n",
    "data_2000_2 = drop_lines(data_2000_2, 'ESTU_NACIMIENTO_ANNO', '196')\n",
    "data_2000_2 = drop_lines(data_2000_2, 'ESTU_NACIMIENTO_ANNO', '197')\n",
    "data_2000_2 = drop_lines(data_2000_2, 'ESTU_NACIMIENTO_ANNO', '197*')\n",
    "data_2000_2 = drop_lines(data_2000_2, 'ESTU_NACIMIENTO_ANNO', '198')\n",
    "data_2000_2 = drop_lines(data_2000_2, 'ESTU_NACIMIENTO_ANNO', '198*')\n",
    "data_2000_2 = drop_lines(data_2000_2, 'ESTU_NACIMIENTO_ANNO', '199')\n",
    "data_2000_2 = drop_lines(data_2000_2, 'ESTU_NACIMIENTO_ANNO', '199*')\n",
    "data_2000_2 = drop_lines(data_2000_2, 'ESTU_NACIMIENTO_ANNO', '2 *7')\n",
    "data_2000_2 = drop_lines(data_2000_2, 'ESTU_NACIMIENTO_ANNO', '2 00')\n",
    "data_2000_2 = drop_lines(data_2000_2, 'ESTU_NACIMIENTO_ANNO', '7')\n",
    "data_2000_2 = drop_lines(data_2000_2, 'ESTU_NACIMIENTO_ANNO', '8')\n",
    "data_2000_2 = drop_lines(data_2000_2, 'ESTU_NACIMIENTO_ANNO', '9')\n",
    "data_2000_2 = drop_lines(data_2000_2, 'ESTU_NACIMIENTO_ANNO', '9 0')\n",
    "data_2000_2 = drop_lines(data_2000_2, 'ESTU_NACIMIENTO_ANNO', '9 2')\n",
    "data_2000_2 = drop_lines(data_2000_2, 'ESTU_NACIMIENTO_ANNO', '9*1')\n",
    "data_2000_2 = drop_lines(data_2000_2, 'ESTU_NACIMIENTO_ANNO', '95')\n",
    "data_2000_2 = drop_lines(data_2000_2, 'ESTU_NACIMIENTO_ANNO', '97')\n",
    "data_2000_2 = drop_lines(data_2000_2, 'ESTU_NACIMIENTO_ANNO', '98')\n",
    "data_2000_2 = drop_lines(data_2000_2, 'ESTU_NACIMIENTO_ANNO', '2980')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['1928', '1930', '1932', '1933', '1934', '1936', '1937', '1938', '1939',\n",
      "       '1940', '1941', '1942', '1943', '1944', '1945', '1946', '1947', '1948',\n",
      "       '1949', '1950', '1951', '1952', '1953', '1954', '1955', '1956', '1957',\n",
      "       '1958', '1959', '1960', '1961', '1962', '1963', '1964', '1965', '1966',\n",
      "       '1967', '1968', '1969', '1970', '1971', '1972', '1973', '1974', '1975',\n",
      "       '1976', '1977', '1978', '1979', '1980', '1981', '1982', '1983', '1984',\n",
      "       '1985', '1986', '1987', '1988', '1989', '1990', '1991', '1996', '1997',\n",
      "       '1998', '1999', '2000'],\n",
      "      dtype='object')\n",
      "1928         1\n",
      "1930         1\n",
      "1932         3\n",
      "1933         2\n",
      "1934         1\n",
      "1936         1\n",
      "1937         1\n",
      "1938        21\n",
      "1939        10\n",
      "1940         4\n",
      "1941         4\n",
      "1942         9\n",
      "1943         6\n",
      "1944        16\n",
      "1945        16\n",
      "1946        20\n",
      "1947        26\n",
      "1948        40\n",
      "1949        31\n",
      "1950        49\n",
      "1951        59\n",
      "1952        87\n",
      "1953        87\n",
      "1954       126\n",
      "1955       138\n",
      "1956       147\n",
      "1957       188\n",
      "1958       214\n",
      "1959       221\n",
      "1960       290\n",
      "         ...  \n",
      "1967       682\n",
      "1968       751\n",
      "1969       883\n",
      "1970       844\n",
      "1971       975\n",
      "1972      1129\n",
      "1973      1239\n",
      "1974      1476\n",
      "1975      1892\n",
      "1976      2343\n",
      "1977      3462\n",
      "1978      5581\n",
      "1979     10551\n",
      "1980     19909\n",
      "1981     38426\n",
      "1982     68871\n",
      "1983    103469\n",
      "1984     60990\n",
      "1985      5461\n",
      "1986       196\n",
      "1987        50\n",
      "1988        53\n",
      "1989        51\n",
      "1990        19\n",
      "1991         1\n",
      "1996         1\n",
      "1997         3\n",
      "1998         1\n",
      "1999         1\n",
      "2000         3\n",
      "Name: ESTU_NACIMIENTO_ANNO, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "\"\"\"I Check the changes\"\"\"\n",
    "print(data_2000_2['ESTU_NACIMIENTO_ANNO'].value_counts().sort_index().index)\n",
    "print(data_2000_2['ESTU_NACIMIENTO_ANNO'].value_counts().sort_index())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\"\"\"\n",
    "print(data_2000_2[''].value_counts().sort_index().index)\n",
    "print(data_2000_2[''].value_counts().sort_index())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\"\"\"\n",
    "print(data_2000_2[''].value_counts().sort_index().index)\n",
    "print(data_2000_2[''].value_counts().sort_index())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\"\"\"\n",
    "print(data_2000_2[''].value_counts().sort_index().index)\n",
    "print(data_2000_2[''].value_counts().sort_index())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['COLE_COD_ICFES', 'IND_ANNO_TERMINO_BACHILLERATO', 'COLE_JORNADA',\n",
       "       'COLE_VALOR_PENSION', 'ESTU_GENERO', 'ESTU_NACIMIENTO_DIA',\n",
       "       'ESTU_NACIMIENTO_MES', 'ESTU_NACIMIENTO_ANNO',\n",
       "       'ESTU_DEPTO_PRESENTACION', 'ESTU_MCPIO_PRESENTACION', 'ESTU_ETNIA',\n",
       "       'ESTU_LIMITA_INVIDENTE', 'ESTU_LIMITA_SORDOINTERPRETE',\n",
       "       'ESTU_LIMITA_SORDONOINTERPRETE', 'ESTU_LIMITA_MOTRIZ', 'PUNT_BIOLOGIA',\n",
       "       'PUNT_MATEMATICAS', 'PUNT_FILOSOFIA', 'PUNT_FISICA', 'PUNT_HISTORIA',\n",
       "       'PUNT_QUIMICA', 'PUNT_LENGUAJE', 'PUNT_GEOGRAFIA',\n",
       "       'COD_INTERDISCIPLINAR', 'PUNT_INTERDISCIPLINAR', 'COD_IDIOMA',\n",
       "       'PUNT_IDIOMA', 'ESTU_IES_COD_DESEADA', 'ESTU_RAZONINSTITUTO',\n",
       "       'ESTU_CARRDESEADA_COD', 'ESTU_CARRDESEADA_RAZON', 'FAMI_PERSONAS_HOGAR',\n",
       "       'FAMI_VIVIENDA_PROPIA', 'FAMI_DEUDA_VIVIENDA', 'FAMI_APORTANTES',\n",
       "       'FAMI_INGRESO_FMILIAR_MENSUAL', 'FAMI_LEE_ESCRIBE_PADRE',\n",
       "       'FAMI_LEE_ESCRIBE_MADRE', 'FAMI_EDUCA_PADRE', 'FAMI_EDUCA_MADRE',\n",
       "       'FAMI_OCUPA_PADRE', 'FAMI_OCUPA_MADRE', 'FAMI_NUM_HERMANOS',\n",
       "       'FAMI_NUM_HERMANOS_EDUSUPERIOR', 'FAMI_POSICION_HERMANOS',\n",
       "       'FAMI_SOST_PERSONAL', 'ESTU_TRABAJA', 'ESTU_ACT_PROX_ANNO',\n",
       "       'COLE_CALENDARIO', 'COLE_BILINGUE', 'COLE_CARACTER',\n",
       "       'COLE_DEPTO_UBICACION', 'COLE_MCPIO_UBICACION', 'ESTU_RESIDE_DEPTO',\n",
       "       'ESTU_RESIDE_MCPIO'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_2000_2.columns"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 + Anaconda",
   "language": "python",
   "name": "pyconda3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
